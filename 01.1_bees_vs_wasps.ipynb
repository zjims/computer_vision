{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true) <img src='https://github.com/PracticumAI/practicumai.github.io/blob/84b04be083ca02e5c7e92850f9afd391fc48ae2a/images/icons/practicumai_computer_vision.png?raw=true' alt='Practicum AI: Computer Vision icon' align='right' width=50>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Concepts\n",
    "\n",
    "You may recall *Practicum AI*'s heroine Amelia, the AI-savvy nutritionist. At the end of our *[Deep Learning Foundations course](https://practicumai.org/courses/deep_learning/)*, Amelia was helping with a computer vision project. Her colleague, an entomologist named Kevin, had a dataset of images of bees and wasps and wanted to classify them.\n",
    "\n",
    "![Image of bees and wasps from the dataset cover image](https://github.com/PracticumAI/deep_learning/blob/main/images/bees_wasps_dataset-cover.png?raw=true)\n",
    "\n",
    "\n",
    "## AI Pathway review for Bees vs Wasps\n",
    "\n",
    "If you have taken out [Getting Started with AI course](https://practicumai.org/courses/getting_started/), you may remember this figure of the AI Application Development Pathway. Let's take a quick review of how we applied this pathway in the case of the Bees vs Wasps example.\n",
    "\n",
    "![AI Application Development Pathway image showing the 7 steps in developing an AI application](https://practicumai.org/getting_started/images/application_dev_pathway.png)\n",
    "\n",
    "1. **Choose a problem to solve:** In this example, we need to classify images as bees, wasps, other insects, or a non-insect. \n",
    "2. **Gather data:** The data for the example come from [Kaggle](https://www.kaggle.com/), a great repository of datasets, code, and models.\n",
    "3. **Clean and prepare the data:** In the *Deep Learning Foundations* course, we assumed that this was done for us. One issue that we ran into was that of class imbalance. There are many more images in some classes than others, leading to a poor performing model.\n",
    "4. **Choose a model:** In the *Deep Learning Foundations* course, we presented the model with little detail. Now that we know more about Convolutional Neural Networks and some other tools are our disposal, we will explore the model in more detail.\n",
    "   * As part of the iterative process among this and the next steps, one thing we noticed is that most of our models were overfittingâ€”performing better on the training data than they did on the testing data. Essentially, the models memorized the training data but did not generalize well to new data that had not been seen. \n",
    "      * In this notebook, we will explore **dropout** as one mechanism to mitigate overfitting.\n",
    "5. **Train the model:** In training the model we may have had a few issues. With so many hyperparameters to tune, it's easy to lose track of what combinations have been tried and how changes impacted model performance. \n",
    "   * In this notebook, we introduce you to [TensorBoard](https://www.tensorflow.org/tensorboard), one popular tool in a class of tools known as **experiment tracking** or **MLOps tools**. These tools help track changes to hyperparameters, the training process, and the data. They allow comparison among runs and can even automate multiple runs for you. Learning to use MLOps tools will help you as you continue to learn more about AI workflows.\n",
    "6. **Evaluate the model:** We will continue to assess how the model performs on the test set and adjust the model and hyperparameters to attempt to produce a better model. However, as noted above in step 3, one issue is the class imbalance.    \n",
    "   * This is a common issue with real data, and in notebook [01.2_stratification.ipynb](01.2_stratification.ipynb), we will explore some methods to handle this.\n",
    "7. **Deploy the model:** We won't get to this stage in this exercise, but hopefully, we will end up with a model that could be deployed and achieve relatively good accuracy at solving the problem.\n",
    "\n",
    "\n",
    "## A refresher\n",
    "\n",
    "If you need a refresher, or haven't taken the *Deep Learning Foundations* course, the final notebook is part of this repository: [DLF_03_bees_vs_wasps.ipynb](DLF_03_bees_vs_wasps.ipynb). However, we will cover what we did before and the new changes as we work through this notebook. Some of the code has been moved into the [helpers_01.py](helpers_01.py) file and is imported below to keep things cleaner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the libraries we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf   # Import the TensorFlow library, which provides tools for deep learning.\n",
    "import pandas as pd  # Import the pandas library, used for data manipulation and analysis.\n",
    "import datetime\n",
    "\n",
    "# Used for data management\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting and visualization.\n",
    "\n",
    " \n",
    "# Import Keras libraries\n",
    "from tensorflow.keras.models import Sequential  # Import the Sequential model: a linear stack of layers from Keras module in TensorFlow.\n",
    "from tensorflow.keras.layers import Dense  # Import the Dense layer: a fully connected neural network layer from Keras module in TensorFlow.\n",
    "from tensorflow.keras.layers import Flatten  # Import the Flatten layer: used to convert input data into a 1D array from Keras module in TensorFlow.\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy  # Import the SparseCategoricalCrossentropy loss function from Keras module in TensorFlow.\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import losses\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import numpy as np \n",
    "\n",
    "# Import helper functions--most of these were in the cells of the DLF_03_bees_vs_wasps.ipynb notebook.\n",
    "# We moved them out of the notebook to enhace readability. \n",
    "import helpers_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jupyter magic commands\n",
    "\n",
    "In Jupyter, the `%` is used as a \"magic\" command. These extend Python on various ways. In this case, Tensorboad functionality is added using `%load_ext tensorboard`\n",
    "\n",
    "Again, [Tensorboard](https://www.tensorflow.org/tensorboard) is the MLOps tool we'll use for experiment tracking in many of these notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting the data\n",
    "\n",
    "Check the \"Getting the data\" section of [DLF_03_bees_vs_wasps.ipynb](DLF_03_bees_vs_wasps.ipynb#2.-Getting-the-data) for details about the dataset and the code used to getting the data if neede. Or you can look at the [helpers_01.py file](helpers_01.py). \n",
    "\n",
    "If you need to download the data, it is [hosted for download from Dropbox here as a `tar.gz` file](https://www.dropbox.com/s/x70hm8mxqhe7fa6/bee_vs_wasp.tar.gz?dl=0). If you need to manually extract the data, you can add a cell and run: `helpers_01.extract_file(\"bee_vs_wasp.tar.gz\", \"data\")`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for the data.\n",
    "# This will look for the data files required for this notebook in some common locations.\n",
    "# If it can't find the data, it will ask if you know where it is. If you do, answer yes and \n",
    "# provide the path to the data (up to and including the `bee_vs_wasp` folder name). If not, \n",
    "# it will ask if you want to download it. If you answer yes, it will download the data and \n",
    "# extract it into your data folder.\"\"\n",
    "\n",
    "data_path = helpers_01.manage_data()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Examine some images\n",
    "\n",
    "Many of the steps in this notebook are written as functions, making it easier to run these steps repeatedly as you work on optimizing the various hyperparameters.\n",
    "\n",
    "The `helpers_01.load_display_data` function takes: \n",
    "* A path to the data--set from above.\n",
    "* The batch size--set as 32 below, but a good hyperparameter to tune.\n",
    "* Target shape for images--set as 80*80 color images below, another possible hyperparameter.\n",
    "* Whether or not to show sample images.\n",
    "\n",
    "It returns training and testing datasets. To help highlight the class imbalance issue, the function has been updated to report the numbers of images and percent of the total in each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The data path should be set from the cell above. \n",
    "# If that failed and you want to set it manually, use the line below.\n",
    "# data_path= \"data/bee_vs_wasp\"\n",
    "\n",
    "X_train, X_test = helpers_01.load_display_data(data_path, batch_size=32, shape=(80,80,3), show_pictures=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_path = 'data/bee_vs_wasp/' # Path to the data.\n",
    "        # This is defined above, you only need to change this if you change datasets\n",
    "    \n",
    "show_pictures = False # We'll turn this off, but change to True if you want them...\n",
    "\n",
    "# Hyperparameters\n",
    "shape = (80,80,3)  # Dimensions to use for the images...the raw data are 80x80\n",
    "                   #  color images, but you could down-sample them\n",
    "                   #  or convert them to black and white if you wanted\n",
    "batch_size = 32  # What batch size to use\n",
    "classes = 4 # We have 4 classes in our dataset: bee, wasp, other_insect, other_noninsect\n",
    "            # Only change this if you change the dataset\n",
    "activation='relu' # The activation function is an important hyperparameter\n",
    "                  # Other activations functions to try: tanh, sigmoid\n",
    "\n",
    "loss=SparseCategoricalCrossentropy(from_logits=False) # Loss function\n",
    "        # Other loss functions to try: losses.CategoricalHinge()\n",
    "        #                              losses.KLDivergence()\n",
    "\n",
    "optimizer='Adagrad' # Optimizer: Adagrad is just an example, others to try are Adam or RMSprop\n",
    "\n",
    "learning_rate=0.001 # Try increasing or decreasing the learning rate by an order of magnitude\n",
    "\n",
    "epochs = 10 # Try running more epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make our model\n",
    "\n",
    "This function creates the model we will use.\n",
    "\n",
    "One hyperparameter to explore is the activation function, which is set when making the model. We start with a ReLU as the default, but you can try others. For simplicity, we will use the same activation function for all but the last layer of the model, but you could change them individually.\n",
    "\n",
    "The last layer will almost always use a Softmax, which makes all the output values between 0 and 1 and sum to 1, transforming them into probabilities of the input belonging to each possible class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(activation='relu', shape=(80,80,3), num_classes=4):\n",
    "    '''Sets up a model. \n",
    "          Takes in an activation function, shape for the input images, and number of classes.\n",
    "          Returns the model.'''\n",
    "    print(\"***********************************************************************\")\n",
    "    print(\"Make model:\")\n",
    "    print(f\"  - Using the activation function: {activation}.\")\n",
    "    print(f\"  - Model will have {num_classes} classes.\")\n",
    "    print(\"***********************************************************************\")\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation=activation, input_shape=shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation=activation),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=activation),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compile and Train the model\n",
    "\n",
    "This step compiles the model, getting it ready for training. The primary hyperparameters here are:\n",
    "* the **loss function** (how we determine how close the predicted output is from the known output values),\n",
    "* the **optimization function** (how we determine what parameters should be updated and how),\n",
    "* the **learning rate** (how much each parameter should be adjusted), \n",
    "* and how many **epochs** should be run (remember, an epoch is a full pass through all the training data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a TensorBoad callback\n",
    "\n",
    "In Tensorflow, callbacks can be used during model training to control a number of things, like changing the learning rate each epoch, stopping training if model accuracy hasn't improved a set amount over a set number of epochs, etc. In this case, we will use a callback to log training data to a folder for TensorBoard to analyze.\n",
    "\n",
    "We'll set the log path, adding the hyperparameter values we want to keep track of as part of the path name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set dropout variable to \"No_dropout\" since we haven't added dropout to the model yet\n",
    "dropout = \"No_dropout\" \n",
    "time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "log_dir = f\"logs/fit_{activation}_{dropout}_{learning_rate}_{epochs}_{time}\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "model, history = helpers_01.compile_train_model(X_train, X_test, model, callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate the model\n",
    "\n",
    "Now that we have trained our model let's evaluate how it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "helpers_01.evaluate_model(X_train, X_test, model, history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. View training metrics in TensorBoard\n",
    "\n",
    "Now that we've run one training cycle, we can open TensorBoard and have a look at the visualizations it provides to evaluate training performance.\n",
    "\n",
    "The detailed instructions for different platforms are in the course content. In general, we use the `tensorboard --logdir ./logs` command to start TensorBoard and then connect in a Web browser. Here's a screenshot of what that might look like:\n",
    "\n",
    "![Screenshot of the TensorBoard web page](images/tensorboard_screenshot.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Explore hyperparameters!\n",
    "\n",
    "OK, we've trained the model once using some decent first guesses. Now, we can see if we can do better by exploring different hyperparameters.\n",
    "\n",
    "While there are methods to explore different hyperparameters systematically and track the results more efficiently, we will rely on some ad-hoc exploration and keep everything in the notebook.\n",
    "\n",
    "The following function pulls all the steps from above into a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def the_whole_shebang(path, batch_size, shape, classes, activation, loss, optimizer, show_pictures=True):\n",
    "    \n",
    "    X_train, X_test = helpers_01.load_display_data(data_path, batch_size, shape, show_pictures)\n",
    "    model = make_model(activation=activation, shape=shape, num_classes=classes)\n",
    "    \n",
    "    # Set dropout variable to \"No_dropout\" since we haven't added dropout to the model yet\n",
    "    dropout = \"No_dropout\" \n",
    "    time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    log_dir = f\"logs/fit_{activation}_{dropout}_{learning_rate}_{epochs}_{time}\"\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model, history = helpers_01.compile_train_model(X_train, X_test, model, loss=loss,\n",
    "                        optimizer=optimizer, learning_rate=learning_rate, epochs=epochs, callbacks=tensorboard_callback)\n",
    "    helpers_01.evaluate_model(X_train, X_test, model, history, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the next cell and change hyperparameters\n",
    "\n",
    "You can copy the next cell multiple times and adjust the hyperparameters to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_path = 'data/bee_vs_wasp/' # Path to the data.\n",
    "        # This is defined above, you only need to change this if you change datasets\n",
    "    \n",
    "show_pictures = True # Show sample images from the dataset? Keep on at first, but may become distracting.\n",
    "                     # Set to False to turn off\n",
    "\n",
    "# Hyperparameters\n",
    "shape = (80,80,3)  # Dimensions to use for the images...the raw data are 80x80\n",
    "                   #  color images, but you could down-sample them\n",
    "                   #  or convert them to black and white if you wanted\n",
    "batch_size = 64  # What batch size to use\n",
    "classes = 4 # We have 4 classes in our dataset: bee, wasp, other_insect, other_noninsect\n",
    "            # Only change this if you change the dataset\n",
    "activation='relu' # The activation function is an important hyperparameter\n",
    "                  # Other activations functions to try: tanh, sigmoid\n",
    "\n",
    "loss=SparseCategoricalCrossentropy(from_logits=False) # Loss function\n",
    "        # Other loss functions to try: losses.CategoricalHinge()\n",
    "        #                              losses.KLDivergence()\n",
    "\n",
    "optimizer='Adagrad' # Optimizer: Adagrad is just an example, others to try are Adam or RMSprop\n",
    "\n",
    "learning_rate=0.001 # Try increasing or decreasing the learning rate by an order of magnitude\n",
    "\n",
    "epochs = 10 # Try running more epochs\n",
    "\n",
    "# Run everything with these hyperparameters\n",
    "the_whole_shebang(data_path, batch_size, shape, classes, activation, loss, optimizer, show_pictures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary so far\n",
    "\n",
    "Some of the points we can take away so far:\n",
    "\n",
    "* Most of the time, our model struggles to do better than about 70% accuracy on the validation data. Accuracy on the training data is closer to 90%. This suggests that our model is overfitting the training data.\n",
    "* Additionally, while 70% doesn't sound too bad, the confusion matrix makes it clear that the model favors predicting the wasp category--more images from the other categories are classified as wasp than the correct cateregory.\n",
    "* This highlights the need to look at different measures of accuracy! What measure is most important can depend on the situation and the implications of making mistakes of different kinds.\n",
    "\n",
    "Before we move on to working more to improve the model, let's take a quick look at the inner workings of the convolutional kernels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. A look inside CNNs\n",
    "To get an idea for what is happening *inside* this model, let's look at a **feature map**. Below we see a vertical edge detection filter applied to a sunflower picture, resulting in a feature map of that image.\n",
    "\n",
    "![Two pictures of a sunflower. On the left is the original image, on the right is the convolved image resulting from applying an edge detecting convolutional filter.](images/filtered_sunflower_nb01.jpg)\n",
    "\n",
    "Imagine you're a detective investigating a scene.  A feature map is like a sketch you create, focusing on specific details that might be clues to solving the case.  In a CNN, the \"case\" is recognizing patterns in an image, and the feature maps capture these patterns at different levels of complexity. Early layers might create feature maps that detect basic edges, corners, or blobs of color. As the network progresses through more layers, the feature maps become more intricate, combining these simpler features to represent more complex objects or shapes.\n",
    "\n",
    "Getting a bit more technical, a feature map is a 2D array of activations produced by applying a convolutional filter to an input image or a previous layer's feature map. It essentially captures the presence and strength of specific visual features the filter is optimized to detect within the input.\n",
    "\n",
    "The **convolutional filters** (also just called \"filters\" or \"kernels\") are small matrices containing learnable weights. The filter \"slides\" across the input image, performing element-wise multiplication with the underlying image data at each position. The result of the multiplication is then passed through an activation function (like ReLU) to introduce non-linearity and help the network learn complex features. A convolutional layer typically has multiple filters, each generating a separate feature map. These feature maps capture different aspects of the input, providing a richer representation of the image.\n",
    "\n",
    "**NOTE**: The above sunflower example could potentially be a bit misleading. While a model *can* and probably will develop a vertical edge detection filter, the model develops it's filter's weights through the same backpropagation process as other deep neural networks. Most of the filters, and their resulting feature maps, will not be as easily interpretable as the vertical edge detection filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the filters from the first layer of the model\n",
    "filters = model.layers[0].get_weights()[0]\n",
    "\n",
    "# Get the first batch of images from the training set\n",
    "conv_images = X_train.take(1)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in conv_images:\n",
    "    images = images.numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "# Get the feature maps from the first layer of the model\n",
    "feature_maps = tf.keras.models.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "feature_maps = feature_maps.predict(images)\n",
    "\n",
    "# Normalize the filters and feature maps. This will make the images more clear.\n",
    "normal_filters = (filters - filters.min()) / (filters.max() - filters.min())\n",
    "normal_feature_maps = (feature_maps - feature_maps.min()) / (feature_maps.max() - feature_maps.min())\n",
    "\n",
    "# Display the filters, images and feature maps\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# ----- Filters -----\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 3, i + 1)  # 3 rows, 3 columns, position 1 to 3 \n",
    "    plt.imshow(normal_filters[:, :, :, i], cmap='gray')\n",
    "    plt.title(f'Filter {i}')\n",
    "    plt.axis('off')\n",
    "\n",
    "# ----- Original Images -----\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 3, i + 4)  # Position 4 to 6\n",
    "    plt.imshow(images[i].astype(\"uint8\"))\n",
    "    plt.title(f'Original Image {i}')\n",
    "    plt.axis('off')\n",
    "\n",
    "# -----  Feature Maps (Image 1) -----\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 3, i + 7)  # Position 7 to 9\n",
    "    plt.imshow(normal_feature_maps[1, :, :, i], cmap='gray')\n",
    "    plt.title(f'Feature Map 1, Channel {i}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Visualizing a CNN')  # Overall title for the plot\n",
    "plt.tight_layout()  # Adjust spacing to prevent overlaps\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with the other hyperparameters in Section 5 above, the number of filters, the size of the filters, and the stride of the filters are all hyperparameters that can be adjusted. You can also add or remove convolutional and pooling layers, or add dropout layers.\n",
    "\n",
    "\n",
    "## 13. Dropout\n",
    "\n",
    "Dropout layers are a regularization technique that helps prevent overfitting by randomly setting a fraction of input units to 0 at each update during training. Here is an example of how to add a dropout layer to the model:\n",
    "    \n",
    "```python\n",
    "   layers.Dropout(0.5) \n",
    "```\n",
    "\n",
    "## 14. Padding and Stride for Convolutional Layers\n",
    "To adjust the stride and padding of the convolutional layers, you can add the `strides` and `padding` arguments to the `Conv2D` layer. The `strides` argument is a tuple of two integers, specifying the strides of the convolution along the height and width. The `padding` argument can be either `'valid'` or `'same'`. `'valid'` means no padding, while `'same'` means the output feature map will have the same spatial dimensions as the input feature map. Here is an example of a convulutional layer with a stride of 2 and padding of `'same'`:\n",
    "    \n",
    "```python\n",
    "    # Replacement Conv2D layer\n",
    "    layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation=activation)\n",
    "    # Replacement MaxPooling2D layer\n",
    "    layers.MaxPooling2D((2, 2), padding='same', strides=(2, 2))\n",
    "```\n",
    "\n",
    "The cell below updates the `make_model` function to include dropout layers, and padding. Feel free to adjust these as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model_2(activation='relu', shape=(80,80,3), num_classes=4):\n",
    "    '''Sets up a model. \n",
    "          Takes in an activation function, shape for the input images, and number of classes.\n",
    "          Returns the model.'''\n",
    "    print(\"***********************************************************************\")\n",
    "    print(\"Make model:\")\n",
    "    print(f\"  - Using the activation function: {activation}.\")\n",
    "    print(f\"  - Model will have {num_classes} classes.\")\n",
    "    print(\"***********************************************************************\")\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), padding='same', activation=activation, input_shape=shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation=activation),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Conv2D(128, (3, 3), padding='same', activation=activation),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=activation),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_model_2()\n",
    "model.summary()\n",
    "\n",
    "def the_whole_shebang(path, batch_size, shape, classes, activation, loss, optimizer, show_pictures=True):\n",
    "    \n",
    "    X_train, X_test = helpers_01.load_display_data(data_path, batch_size, shape, show_pictures)\n",
    "    model = make_model(activation=activation, shape=shape, num_classes=classes)\n",
    "    \n",
    "    # Set dropout variable to \"W_dropout\" now that we have added dropout to the model\n",
    "    dropout = \"W_dropout\" \n",
    "    time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    log_dir = f\"logs/fit_{activation}_{dropout}_{learning_rate}_{epochs}_{time}\"\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model, history = helpers_01.compile_train_model(X_train, X_test, model, loss=loss,\n",
    "                        optimizer=optimizer, learning_rate=learning_rate, epochs=epochs, callbacks=tensorboard_callback)\n",
    "    helpers_01.evaluate_model(X_train, X_test, model, history, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_path = 'data/bee_vs_wasp/' # Path to the data.\n",
    "        # This is defined above, you only need to change this if you change datasets\n",
    "    \n",
    "show_pictures = True # Show sample images from the dataset? Keep on at first, but may become distracting.\n",
    "                     # Set to False to turn off\n",
    "\n",
    "# Hyperparameters\n",
    "shape = (80,80,3)  # Dimensions to use for the images...the raw data are 80x80\n",
    "                   #  color images, but you could down-sample them\n",
    "                   #  or convert them to black and white if you wanted\n",
    "batch_size = 64  # What batch size to use\n",
    "classes = 4 # We have 4 classes in our dataset: bee, wasp, other_insect, other_noninsect\n",
    "            # Only change this if you change the dataset\n",
    "activation='relu' # The activation function is an important hyperparameter\n",
    "                  # Other activations functions to try: tanh, sigmoid\n",
    "\n",
    "loss=SparseCategoricalCrossentropy(from_logits=False) # Loss function\n",
    "        # Other loss functions to try: losses.CategoricalHinge()\n",
    "        #                              losses.KLDivergence()\n",
    "\n",
    "optimizer='Adagrad' # Optimizer: Adagrad is just an example, others to try are Adam or RMSprop\n",
    "\n",
    "learning_rate=0.001 # Try increasing or decreasing the learning rate by an order of magnitude\n",
    "\n",
    "epochs = 10 # Try running more epochs\n",
    "\n",
    "# Run everything with these hyperparameters\n",
    "the_whole_shebang(data_path, batch_size, shape, classes, activation, loss, optimizer, show_pictures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Conclusion\n",
    "\n",
    "Well...50% dropout might be too much! Experiment and see what improvement you can make, but there is only so much hyperparameter tuning can do! Addressing the data is probably going to be more important in this case!\n",
    "\n",
    "Using Tensorboard, you can keep track of what hyperparemeters are changed and monitor the impact of these changes on model training and performance. Once you are satisfied, contiune to the notebook [01.2_data_imbalance.ipynb](01.2_data_imbalance.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Exercise\n",
    "If you found this exercise pretty simple, try editing the code in this notebook such that our function from Section 7 (*the_whole_shebang*) can control the Dropout rate, stride, and padding of the convolutional layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
